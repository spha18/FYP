{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9f353bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c82083a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(trainX, trainy, testX, testy):\n",
    "    verbose, epochs, batch_size = 0, 15, 64\n",
    "    n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(100, input_shape=(n_timesteps,n_features)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(n_outputs, activation='softmax'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # fit network\n",
    "    model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    # evaluate model\n",
    "    _, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=2)\n",
    "    return accuracy\n",
    "\n",
    "# summarize scores\n",
    "def summarize_results(scores):\n",
    "    print(scores)\n",
    "    m, s = np.mean(scores), np.std(scores)\n",
    "    print('Accuracy: %.3f%% (+/-%.3f)' % (m, s))\n",
    "\n",
    "# run an experiment\n",
    "def run_experiment(repeats=10):\n",
    "    # repeat experiment\n",
    "\n",
    "    scores = list()\n",
    "    for r in range(repeats):\n",
    "        trainX, testX, trainy, testy = train_test_split(X, y, test_size=0.2)\n",
    "        print(\"\".join([\"Features: \",f\"{X.shape[2]}\"]))\n",
    "        print(\"\".join([\"Timesteps: \",f\"{X.shape[1]}\"]))\n",
    "        print(\"\".join([\"Samples: \",f\"{X.shape[0]}\",\" (\",f\"{trainX.shape[0]}\",\" Train, \",f\"{testX.shape[0]}\",\" Test)\"]))\n",
    "        print(\"\".join([\"Training data: \",f\"{np.sum(trainy[:,1])}\",\" ES (\",f\"{np.mean(trainy[:,1]):.2%}\",\"), \",f\"{np.sum(trainy[:,0])}\",\" PNES (\",f\"{np.mean(trainy[:,0]):.2%}\",\")\"]))\n",
    "        print(\"\".join([\"Testing data: \",f\"{np.sum(testy[:,1])}\",\" ES (\",f\"{np.mean(testy[:,1]):.2%}\",\"), \",f\"{np.sum(testy[:,0])}\",\" PNES (\",f\"{np.mean(testy[:,0]):.2%}\",\")\"]))\n",
    "        score = evaluate_model(trainX, trainy, testX, testy)\n",
    "        score = score * 100.0\n",
    "        print('>#%d: %.3f' % (r+1, score))\n",
    "        print(\"\\n\")\n",
    "        scores.append(score)\n",
    "    # summarize results\n",
    "    summarize_results(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a286ec81",
   "metadata": {},
   "outputs": [],
   "source": [
    "npzfile = np.load(\"./Datasets/Pilot_Pose_Video_RolAvg100.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "940aa7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = npzfile[npzfile.files[0]]\n",
    "y = npzfile[npzfile.files[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19be9118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: 75\n",
      "Timesteps: 2170\n",
      "Samples: 27 (21 Train, 6 Test)\n",
      "Training data: 13.0 ES (61.90%), 8.0 PNES (38.10%)\n",
      "Testing data: 3.0 ES (50.00%), 3.0 PNES (50.00%)\n",
      "1/1 - 0s - loss: 0.8649 - accuracy: 0.5000\n",
      ">#1: 50.000\n",
      "\n",
      "\n",
      "Features: 75\n",
      "Timesteps: 2170\n",
      "Samples: 27 (21 Train, 6 Test)\n",
      "Training data: 11.0 ES (52.38%), 10.0 PNES (47.62%)\n",
      "Testing data: 5.0 ES (83.33%), 1.0 PNES (16.67%)\n",
      "1/1 - 0s - loss: 0.8611 - accuracy: 0.5000\n",
      ">#2: 50.000\n",
      "\n",
      "\n",
      "Features: 75\n",
      "Timesteps: 2170\n",
      "Samples: 27 (21 Train, 6 Test)\n",
      "Training data: 12.0 ES (57.14%), 9.0 PNES (42.86%)\n",
      "Testing data: 4.0 ES (66.67%), 2.0 PNES (33.33%)\n",
      "1/1 - 0s - loss: 0.6269 - accuracy: 0.6667\n",
      ">#3: 66.667\n",
      "\n",
      "\n",
      "Features: 75\n",
      "Timesteps: 2170\n",
      "Samples: 27 (21 Train, 6 Test)\n",
      "Training data: 13.0 ES (61.90%), 8.0 PNES (38.10%)\n",
      "Testing data: 3.0 ES (50.00%), 3.0 PNES (50.00%)\n",
      "1/1 - 0s - loss: 0.6511 - accuracy: 0.6667\n",
      ">#4: 66.667\n",
      "\n",
      "\n",
      "Features: 75\n",
      "Timesteps: 2170\n",
      "Samples: 27 (21 Train, 6 Test)\n",
      "Training data: 14.0 ES (66.67%), 7.0 PNES (33.33%)\n",
      "Testing data: 2.0 ES (33.33%), 4.0 PNES (66.67%)\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x0000021EED1789D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 - 1s - loss: 1.0921 - accuracy: 0.1667\n",
      ">#5: 16.667\n",
      "\n",
      "\n",
      "Features: 75\n",
      "Timesteps: 2170\n",
      "Samples: 27 (21 Train, 6 Test)\n",
      "Training data: 14.0 ES (66.67%), 7.0 PNES (33.33%)\n",
      "Testing data: 2.0 ES (33.33%), 4.0 PNES (66.67%)\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x0000021EEE25E5E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 - 0s - loss: 0.9984 - accuracy: 0.3333\n",
      ">#6: 33.333\n",
      "\n",
      "\n",
      "Features: 75\n",
      "Timesteps: 2170\n",
      "Samples: 27 (21 Train, 6 Test)\n",
      "Training data: 12.0 ES (57.14%), 9.0 PNES (42.86%)\n",
      "Testing data: 4.0 ES (66.67%), 2.0 PNES (33.33%)\n",
      "1/1 - 0s - loss: 0.5052 - accuracy: 0.8333\n",
      ">#7: 83.333\n",
      "\n",
      "\n",
      "Features: 75\n",
      "Timesteps: 2170\n",
      "Samples: 27 (21 Train, 6 Test)\n",
      "Training data: 13.0 ES (61.90%), 8.0 PNES (38.10%)\n",
      "Testing data: 3.0 ES (50.00%), 3.0 PNES (50.00%)\n",
      "1/1 - 0s - loss: 0.5172 - accuracy: 0.6667\n",
      ">#8: 66.667\n",
      "\n",
      "\n",
      "Features: 75\n",
      "Timesteps: 2170\n",
      "Samples: 27 (21 Train, 6 Test)\n",
      "Training data: 12.0 ES (57.14%), 9.0 PNES (42.86%)\n",
      "Testing data: 4.0 ES (66.67%), 2.0 PNES (33.33%)\n",
      "1/1 - 0s - loss: 0.6228 - accuracy: 0.6667\n",
      ">#9: 66.667\n",
      "\n",
      "\n",
      "Features: 75\n",
      "Timesteps: 2170\n",
      "Samples: 27 (21 Train, 6 Test)\n",
      "Training data: 12.0 ES (57.14%), 9.0 PNES (42.86%)\n",
      "Testing data: 4.0 ES (66.67%), 2.0 PNES (33.33%)\n",
      "1/1 - 0s - loss: 0.5836 - accuracy: 0.5000\n",
      ">#10: 50.000\n",
      "\n",
      "\n",
      "[50.0, 50.0, 66.66666865348816, 66.66666865348816, 16.66666716337204, 33.33333432674408, 83.33333134651184, 66.66666865348816, 66.66666865348816, 50.0]\n",
      "Accuracy: 55.000% (+/-18.333)\n"
     ]
    }
   ],
   "source": [
    "run_experiment()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
